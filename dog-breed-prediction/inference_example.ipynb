{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "port = 5000\n",
    "# Note: Sometimes I use port 5001 locally, but flask is typically 5000 ^ set your port with the variable above\n",
    "\n",
    "###### To Use:\n",
    "# docker pull jthet/hurricane-prediction:latest\n",
    "# docker run -p 5000:5000 -it --rm jthet/hurricane-prediction:latest\n",
    "\n",
    "# Inference server must be running to execute the requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route: /help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"/model/change\": {\n",
      "    \"description\": \"Changes the TensorFlow model used by the server.\",\n",
      "    \"example\": \"curl -X POST -H 'Content-Type: application/json' -d '{\\\"model_name\\\": \\\"inception\\\"}' http://127.0.0.1:5001/model/change\",\n",
      "    \"method\": \"POST\"\n",
      "  },\n",
      "  \"/model/info\": {\n",
      "    \"description\": \"Provides basic information about the currently loaded TensorFlow model.\",\n",
      "    \"example\": \"curl http://127.0.0.1:5000/model/info\",\n",
      "    \"method\": \"GET\"\n",
      "  },\n",
      "  \"/model/models\": {\n",
      "    \"description\": \"Lists the available TensorFlow models that users can switch to.\",\n",
      "    \"example\": \"curl http://127.0.0.1:5000/model/models\",\n",
      "    \"method\": \"GET\"\n",
      "  },\n",
      "  \"/model/predict\": {\n",
      "    \"description\": \"Predicts the breed of a dog given an image uploaded by the user.\",\n",
      "    \"example\": \"curl -X POST -F 'image=@./data/images/affenpinscher-1.jpg' http://localhost:5000/model/predict\",\n",
      "    \"method\": \"POST\"\n",
      "  },\n",
      "  \"/model/summary\": {\n",
      "    \"description\": \"Provides a textual summary of the currently loaded TensorFlow model's architecture.\",\n",
      "    \"example\": \"curl http://127.0.0.1:5000/model/summary\",\n",
      "    \"method\": \"GET\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Provides an overview and usage examples for the available API endpoints.\n",
    "\n",
    "Example: curl http://127.0.0.1:5000/help\n",
    "'''\n",
    "url = f'http://127.0.0.1:{port}/help'\n",
    "response = requests.get(url)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route: /model/info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Predict the breed of a dog using the inception tensorflow model.', 'name': 'inception', 'non-trainable parameters:': '21802784', 'total parameters:': '22048664', 'trainable parameters:': '245880', 'version': 'v1'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Provides basic information about the currently loaded TensorFlow model.\n",
    "\n",
    "GET: Returns a JSON object with the model's version, name, description,\n",
    "total number of parameters, number of trainable parameters, and number of non-trainable parameters.\n",
    "\n",
    "Example: curl http://127.0.0.1:5000/model/info\n",
    "'''\n",
    "url = f'http://127.0.0.1:{port}/model/info'\n",
    "response = requests.get(url)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route: /model/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'available_models': ['vgg16', 'inception', 'lenet5'], 'currently_loaded': 'inception', 'default_model': 'inception', 'note': 'inception is the default model loaded in and is the most accurate.'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lists the available TensorFlow models that users can switch to.\n",
    "\n",
    "GET: Returns a JSON object listing all available models and indicating the default model.\n",
    "\n",
    "Example: curl http://127.0.0.1:5000/model/models\n",
    "\"\"\"\n",
    "url = f'http://127.0.0.1:{port}/model/models'\n",
    "response = requests.get(url)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route: /model/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"Model: \\\"sequential_11\\\"\",\n",
      "  \"_________________________________________________________________\",\n",
      "  \" Layer (type)                Output Shape              Param #   \",\n",
      "  \"=================================================================\",\n",
      "  \" resizing_5 (Resizing)       (None, 299, 299, 3)       0         \",\n",
      "  \"                                                                 \",\n",
      "  \" inception_v3 (Functional)   (None, 2048)              21802784  \",\n",
      "  \"                                                                 \",\n",
      "  \" dropout_1 (Dropout)         (None, 2048)              0         \",\n",
      "  \"                                                                 \",\n",
      "  \" dense_25 (Dense)            (None, 120)               245880    \",\n",
      "  \"                                                                 \",\n",
      "  \"=================================================================\",\n",
      "  \"Total params: 22048664 (84.11 MB)\",\n",
      "  \"Trainable params: 245880 (960.47 KB)\",\n",
      "  \"Non-trainable params: 21802784 (83.17 MB)\",\n",
      "  \"_________________________________________________________________\",\n",
      "  \"\"\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Provides a textual summary of the currently loaded TensorFlow model's architecture.\n",
    "\n",
    "GET: Returns a JSON array where each element is a string describing a layer in the model's architecture.\n",
    "\n",
    "Example: curl http://127.0.0.1:5000/model/summary\n",
    "\"\"\"\n",
    "url = f'http://127.0.0.1:{port}/model/summary'\n",
    "response = requests.get(url)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route: /model/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"affenpinscher\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Classifies an image of a dog by the dog's breed.\n",
    "\n",
    "POST: Expects a multipart/form-data request with an image file under the key \"image\".\n",
    "Returns a JSON object with the classification result and a qualitative assessment of confidence.\n",
    "\n",
    "Example: curl -X POST -F \"image=@./data/damage/-93.795_30.03779.jpeg\" http://localhost:5001/model/predict\n",
    "'''\n",
    "# damaged\n",
    "#image_path = './data/images/affenpinscher-1.jpg'\n",
    "\n",
    "# not damaged\n",
    "image_path = './data/images/affenpinscher-1.jpg'\n",
    "\n",
    "url = f'http://127.0.0.1:{port}/model/predict'\n",
    "\n",
    "# Open the image in binary mode\n",
    "with open(image_path, 'rb') as f:\n",
    "    files = {'image': (image_path, f, 'image/jpeg')}\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route: /model/change\n",
    "\n",
    "changing to lenet5 (from alt_lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"message\": \"Model changed to inception successfully\",\n",
      "  \"model_path\": \"models/inception.keras\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Changes the TensorFlow model used by the server.\n",
    "\n",
    "POST: Expects a JSON object with a key \"model_name\" that specifies the name of the new model to load.\n",
    "Returns a JSON object with a message indicating successful model change and the path to the new model.\n",
    "\n",
    "Example: curl -X POST -H 'Content-Type: application/json' -d '{\"model_name\": \"inception\"}' http://127.0.0.1:5000/model/change\n",
    "\"\"\"\n",
    "\n",
    "url = f'http://127.0.0.1:{port}/model/change'\n",
    "data = {'model_name': 'inception'}\n",
    "response = requests.post(url, json=data, headers={'Content-Type': 'application/json'})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Predict the breed of a dog using the inception tensorflow model.', 'name': 'inception', 'non-trainable parameters:': '21802784', 'total parameters:': '22048664', 'trainable parameters:': '245880', 'version': 'v1'}\n"
     ]
    }
   ],
   "source": [
    "url = f'http://127.0.0.1:{port}/model/info'\n",
    "response = requests.get(url)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"Airedale\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_path = './data/images/Airedale-1.jpg'\n",
    "\n",
    "url = f'http://localhost:{port}/model/predict'\n",
    "\n",
    "# Open the image in binary mode\n",
    "with open(image_path, 'rb') as f:\n",
    "    files = {'image': (image_path, f, 'image/jpeg')}\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that above, the prediction is different from the first prediction in the /model/predict section with the alt-lenet 5 model. \n",
    "\n",
    "\n",
    "This verifies the model was changed. We can also change to Vgg, Resnet, and Ann models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model changed to inception successfully', 'model_path': 'models/inception.keras'}\n",
      "{'description': 'Predict the breed of a dog using the inception tensorflow model.', 'name': 'inception', 'non-trainable parameters:': '21802784', 'total parameters:': '22048664', 'trainable parameters:': '245880', 'version': 'v1'}\n",
      "{\n",
      "  \"result\": \"Airedale\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = f'http://127.0.0.1:{port}/model/change'\n",
    "data = {'model_name': 'inception'}\n",
    "response = requests.post(url, json=data, headers={'Content-Type': 'application/json'})\n",
    "print(response.json())\n",
    "\n",
    "url = f'http://127.0.0.1:{port}/model/info'\n",
    "response = requests.get(url)\n",
    "print(response.json())\n",
    "\n",
    "image_path = './data/images/Airedale-1.jpg'\n",
    "url = f'http://localhost:{port}/model/predict'\n",
    "\n",
    "# Open the image in binary mode\n",
    "with open(image_path, 'rb') as f:\n",
    "    files = {'image': (image_path, f, 'image/jpeg')}\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
