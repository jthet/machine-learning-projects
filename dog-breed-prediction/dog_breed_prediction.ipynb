{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "images_dir = \"./data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_info(image_file):\n",
    "    im = Image.open(f'{image_file}')\n",
    "    print(\"Image Format: \", im.format)\n",
    "    print(\"Image Mode: \", im.mode)\n",
    "    print(\"Image Size: \", im.size)\n",
    "    data = image.imread(f'{image_file}')\n",
    "\n",
    "    print(\"datatype: \", data.dtype)\n",
    "    print(\"shape: \", data.shape)\n",
    "\n",
    "    pyplot.imshow(data)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image_info(f'{images_dir}affenpinscher-7.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image_info(f'{images_dir}American Staffordshire terrier-1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image_info(f'{images_dir}Newfoundland-148.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def gather_image_info(directory):\n",
    "    image_data = []\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    info = {\n",
    "                        'Filename': filename,\n",
    "                        'File Type': img.format,\n",
    "                        'Shape': img.size,\n",
    "                        'Image Mode': img.mode\n",
    "                    }\n",
    "                    image_data.append(info)\n",
    "            except IOError:\n",
    "                print(f\"Cannot open {filename}\")\n",
    "                \n",
    "    df = pd.DataFrame(image_data)\n",
    "    return df\n",
    "\n",
    "\n",
    "image_info_df = gather_image_info(images_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_info_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_jpeg_images = image_info_df[image_info_df['File Type'] != 'JPEG']\n",
    "print(not_jpeg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image_info(f'{images_dir}Shetland sheepdog-23.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that from what is shown above, the image \"Shetland sheepdog-23.jpg\" is not like the rest of the images as it has 4 color channels and is a PNG image. As this is the only image like this, we will remove the image from the data set. This is curious because the image ends with the '.jpg' file type, but it has 4 color channels. \n",
    "\n",
    "Other than that everything looks good. ALl images seem to be JPEG images with 3 color channels, RGB. One issue is that the images are all of different sizes, so we will have to resize all of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be resizing the images to (224, 224, 3)\n",
    "img_width, img_height = 224, 224 \n",
    "channels = 3\n",
    "image_arr_size= img_width * img_height * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_images_and_labels(directory, exclude_file='Shetland sheepdog-23.jpg'):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith('.jpg') and filename != exclude_file:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            with Image.open(file_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img = img.resize((224, 224))\n",
    "\n",
    "                images.append(np.array(img))\n",
    "            \n",
    "                label = filename.split('-')[0]\n",
    "                labels.append(label)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_images_and_labels(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loaded\", images.shape[0], \"images.\")\n",
    "print(\"Images shape:\", images.shape[1:])\n",
    "print(\"Labels:\", labels)\n",
    "print(f\"There are {len(np.unique(labels))} unique labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labels_pd = pd.DataFrame(labels)\n",
    "labels_pd.info()\n",
    "labels_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[1][1][1]) # first image, on pixel x=1, y=1, gives the RGB values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image_array):\n",
    "    data_all_resized = []\n",
    "    for image in image_array:\n",
    "        image_resized = np.array(image, dtype=np.float32) / 255.0\n",
    "        img_array = np.array(image_resized)\n",
    "        data_all_resized.append(img_array)\n",
    "        \n",
    "    return np.array(data_all_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = normalize(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[1][1][1]) # images are now normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data for testing and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: gonna try using train_test_split because I like it, may have memory issues but we'll see*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = images\n",
    "y = labels\n",
    "\n",
    "print(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At this point we have:\n",
    "\n",
    "- Loaded the data, visualized it, checked for characteristics such as image size, format, etc.\n",
    "- Put the data into python data types (np.arrays) as the variables data_all and labels_all, which holds all the data.\n",
    "- Rescaled the data to (224, 224, 3)\n",
    "- Normalized the data\n",
    "- Split the data into testing and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model design, training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From class notes: \n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    " # Define a callback function to print weights and biases at the end of each epoch\n",
    "def print_weights_and_biases(epoch, logs):\n",
    "    if epoch % 1 == 0:  # Print every epoch\n",
    "        print(f\"\\nWeights and Biases at the end of Epoch {epoch}:\")\n",
    "        for layer in model.layers:\n",
    "            print(f\"Layer: {layer.name}\")\n",
    "            weights, biases = layer.get_weights()\n",
    "            print(f\"Weights:\\n{weights}\")\n",
    "            print(f\"Biases:\\n{biases}\")\n",
    "\n",
    "# Create a LambdaCallback to call the print_weights_and_biases function\n",
    "print_weights_callback = LambdaCallback(on_epoch_end=print_weights_and_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# image_arr_size = 128*128*3\n",
    "image_size = (224, 224, 3)\n",
    "image_arr_size = img_width * img_height * channels\n",
    "\n",
    "\n",
    "Ann = Sequential() # initialize model\n",
    "\n",
    "Ann.add(Flatten(input_shape=image_size)) # input layer\n",
    "\n",
    "Ann.add(Dense(512, activation='relu', input_shape=(image_arr_size,)))\n",
    "Ann.add(Dense(256, activation='relu'))\n",
    "Ann.add(Dense(128, activation='relu'))\n",
    "Ann.add(Dense(64, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "Ann.add(Dense(120, activation='softmax')) # using softmax because its a multi-classification problemAnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "if os.path.isfile(\"./models/Ann.keras\"):\n",
    "    Ann = load_model('./models/Ann.keras')\n",
    "\n",
    "else: # this takes like an hour to run \n",
    "    Ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    Ann.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=64, verbose=2)\n",
    "    Ann.save(\"./models/Ann.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
